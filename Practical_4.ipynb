{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Practical 4: Anomaly Detection using Autoencoder (LSTM example from PDF)\n",
        "# Colab-ready: Paste into one notebook cell and run\n",
        "# ============================\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed\n",
        "\n",
        "csv_path = '/content/GOOG.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "print(\"Loaded CSV shape:\", df.shape)\n",
        "display(df.head())\n",
        "\n",
        "\n",
        "df = df[['Date', 'Close']]\n",
        "print(\"\\nColumns after selecting Date and Close:\")\n",
        "display(df.head())\n",
        "df.info()\n",
        "\n",
        "\n",
        "print(\"\\nDate range in dataset:\", df['Date'].min(), \"to\", df['Date'].max())\n",
        "train = df.loc[df['Date'] <= '2017-12-24'].copy()\n",
        "test  = df.loc[df['Date'] > '2017-12-24'].copy()\n",
        "print(\"Train shape:\", train.shape, \"Test shape:\", test.shape)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(np.array(train['Close']).reshape(-1,1))\n",
        "\n",
        "train['Close'] = scaler.transform(np.array(train['Close']).reshape(-1,1))\n",
        "test['Close']  = scaler.transform(np.array(test['Close']).reshape(-1,1))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(train['Date'], train['Close'], label='scaled - train')\n",
        "plt.xticks([], [])\n",
        "plt.legend()\n",
        "plt.title('Scaled Close (Train)')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "TIME_STEPS = 30\n",
        "\n",
        "def create_sequences(X, y, time_steps=TIME_STEPS):\n",
        "    X_out, y_out = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        X_out.append(X.iloc[i:(i+time_steps)].values)\n",
        "        y_out.append(y.iloc[i+time_steps])\n",
        "    return np.array(X_out), np.array(y_out)\n",
        "\n",
        "X_train, y_train = create_sequences(train[['Close']], train['Close'])\n",
        "X_test,  y_test  = create_sequences(test[['Close']], test['Close'])\n",
        "\n",
        "print(\"Training input shape: \", X_train.shape)\n",
        "print(\"Testing  input shape: \", X_test.shape)\n",
        "\n",
        "\n",
        "print(\"\\nExample sequence (last training sample):\")\n",
        "print(X_train[-1].reshape(-1))\n",
        "\n",
        "\n",
        "np.random.seed(21)\n",
        "tf.random.set_seed(21)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, activation='tanh', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(RepeatVector(X_train.shape[1]))\n",
        "model.add(LSTM(128, activation='tanh', return_sequences=True))\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(TimeDistributed(Dense(X_train.shape[2])))\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
        "model.summary()\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    X_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, mode='min')],\n",
        "    shuffle=False,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "X_train_pred = model.predict(X_train)\n",
        "train_mae_loss = np.mean(np.abs(X_train_pred - X_train), axis=(1,2))\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.hist(train_mae_loss, bins=50)\n",
        "plt.xlabel('Train MAE loss')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.title('Histogram of training reconstruction error')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "threshold = np.max(train_mae_loss)\n",
        "print('Reconstruction error threshold (max):', threshold)\n",
        "\n",
        "\n",
        "X_test_pred = model.predict(X_test, verbose=1)\n",
        "test_mae_loss = np.mean(np.abs(X_test_pred - X_test), axis=(1,2))\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.hist(test_mae_loss, bins=50)\n",
        "plt.xlabel('Test MAE loss')\n",
        "plt.ylabel('Number of samples')\n",
        "plt.title('Histogram of test reconstruction error')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "anomaly_df = pd.DataFrame(test.iloc[TIME_STEPS:].reset_index(drop=True).copy())\n",
        "anomaly_df['loss'] = test_mae_loss\n",
        "anomaly_df['threshold'] = threshold\n",
        "anomaly_df['anomaly'] = anomaly_df['loss'] > anomaly_df['threshold']\n",
        "\n",
        "anomalies = anomaly_df.loc[anomaly_df['anomaly'] == True]\n",
        "print(\"\\nNumber of anomalies detected in test set:\", anomalies.shape[0])\n",
        "display(anomalies.head())\n",
        "\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=anomaly_df['Date'], y=scaler.inverse_transform(anomaly_df['Close'].values.reshape(-1,1)).flatten(),\n",
        "                         name='Close price'))\n",
        "fig.add_trace(go.Scatter(x=anomalies['Date'],\n",
        "                         y=scaler.inverse_transform(anomalies['Close'].values.reshape(-1,1)).flatten(),\n",
        "                         mode='markers', name='Anomaly', marker=dict(color='red', size=6)))\n",
        "fig.update_layout(showlegend=True, title='Detected anomalies (Autoencoder based)')\n",
        "fig.show()\n",
        "\n",
        "\n",
        "model.save('/content/lstm_autoencoder_model')\n",
        "print(\"Model saved to /content/lstm_autoencoder_model\")\n"
      ],
      "metadata": {
        "id": "pnkp6isToD_l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}